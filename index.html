---
---
<!DOCTYPE html>
<html>

<head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Avaje-metric.github.io : Website for Avaje Metrics">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Avaje Metrics - Metrics for the JVM masses</title>
</head>

<body>

<!-- HEADER -->
<div id="header_wrap" class="outer">
    <header class="inner">
        <a id="forkme_banner" href="https://github.com/avaje-metric">View on GitHub</a>

        <h1 id="project_title">Avaje Metrics</h1>

        <h2 id="project_tagline">Production metrics on the JVM</h2>

    </header>
</div>

<!-- MAIN CONTENT -->
<div id="main_content_wrap" class="outer">
    <section id="main_content" class="inner">
        <h2>Overview</h2>

        <p>
            This project started as a fork of https://github.com/codahale/metrics but became significantly different.
            Frequent reporting of metrics meant that Avaje Metrics has generally moved away from Moving Averages and
            Histograms/percentiles to relatively simpler and cheaper counters (count, total, mean, max). Additionally
            <code>BucketTimedMetric</code> can be used if needed to provide a clear picture of how latency is
            distributed (because generally it is not 'normally distributed').
        </p>

        <h4>Be aware that:</h4>
        <ul>
            <li>Statistics can lie</li>
            <li>Latency is often not normally distributed (bell curve)</li>
            <li>If you don't collect metrics frequently then interpreting what an 'average' or a 'max' value actually
                means
                can be difficult and potentially misleading.
            </li>
        </ul>

        <h4>LongAdder</h4>

        <p>
            <code>LongAdder</code> and <code>LongMaxUpdater</code> are important implementation details that make
            statistical counters viable in
            production with low overhead and avoiding contention. There are alternatives but for Avaje Metrics these
            are the
            enabling factor that make this viable on busy multicore/multi-threaded JVM applications. Thankfully they
            have been provided to us
            by some clever folks - thanks Doug Lea and friends!!
        </p>

        <h2>Design Goals</h2>
        <ul>
            <li>Collect metrics in production with low overhead
            <li>
                Report metrics frequently to enable reasonable interpretation (Statistics can be misleading)
            </li>
            <li>
                Keep it simple to use
            </li>
            <li>
                Option to use an agent/enhancement to automatically instrument an existing JAX-RS or Spring
                application
            </li>
        </ul>

        <h3>
            Collect metrics in Production
        </h3>
        <blockquote>
            It is important that metrics collection must not add contention or blow out your memory.
        </blockquote>
        <p>
            To collect metrics in production it is important to keep the overhead low and for the statistical counters
            to not introduce contention. Thankfully Doug Lea and friends have built some counters to do exactly what
            we need as part of JSR166e/JDK8. Avaje Metrics makes use of <code>LongAdder</code> and <code>LongMaxUpdater</code> (backported from
            JDK8). Some might say that Avaje Metrics is an glorified wrapper for LongAdder and LongMaxUpdater.
        </p>

        <h3>
            Report metrics frequently
        </h3>

        <p>
            When metrics are reported relatively frequently then the ability to reason and interpret simple count,
            total, mean and max values increases. Conversely, if instead a mean and max value related to a long period
            of time like 1 hour then frequently they become relatively meaningless to interpret. This is due to
            latency generally not being statistically 'normally' distributed. The argument for using percentiles and
            histograms is strong if you don't collect metrics frequently enough.
        </p>

        <p>
            Note that <code>BucketTimedMetric</code> provides a nice alternative to Histograms/Percentiles and I expect
            users will
            frequently look to using BucketTimedMetric on things like web/rest endpoints.
        </p>


        <h3>
            Keep it simple
        </h3>
        <p>
            Simple is always good but if instrumenting your application is too much effort you won't be afforded the
            time to actually do it.  Adding the metrics code is easy but adding timing metrics automatically via enhancement can be
            next to no development effort (so you can get going fast and let the numbers show their value to the business).
        </p>
        <ul>
            <li>Easy to add metrics via code</li>
            <li>Easy to add timing metrics automatically via agent enhancement</li>
            <li>Keep the internals simple - use LongAdder, LongMaxUpdater to be confident this thing isn't going to
                adversely impact
                performance
            </li>
        </ul>

        <h3>
            Agent/Enhancement
        </h3>

        <p>
            Use the metrics agent to instrument classes annotated with <code>@Singleton</code>, JAX-RS
            <code>@Path</code>,
            <code>@Consumes</code>, <code>@Produces</code> or Spring sterotypes <code>@Service</code>,
            <code>@Component</code>, <code>@Repository</code> etc. This provides an
            way to try it out on your existing application with little development effort.
        </p>

        <h2>Business drivers</h2>
        <p>
            For developers collecting metrics on your application can be good fun and very interesting. It is worth
            remembering that there are important questions and business drivers to motivate the collection and reporting
            of these metrics.
        </p>
        <ul>
            <li>
                How is the application currently performing in Production (relative to some baseline)
            </li>
            <li>When do Seasonal/peak loads occur and effect do they have</li>
            <li>Can performance trends be detected due to software releases, configuration changes, growing data</li>
            <li>During development can likely performance issues be detected</li>
            <li>What is the maximum load the system can handle</li>
            <li>Are there specific SLA requirements that need to be monitored
            </li>
        </ul>

        <h2>Getting Started</h2>

        <h3>1. Maven dependencies</h3>
        <p>
        Add the following 2 dependencies to your project.
        </p>
        {% highlight xml %}



        {% endhighlight %}
    </section>
</div>

<!-- FOOTER  -->
<div id="footer_wrap" class="outer">
    <footer class="inner">
        <p>At some point metrics collection will become the 'norm'</p>
    </footer>
</div>


</body>
</html>
